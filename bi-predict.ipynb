{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMmtvpLPINtGzby4p0H5JgZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Do-cc/cc/blob/master/bi-predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRkHP91tAemd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "37a50d87-7854-4df2-80e0-aaa1ca54324f"
      },
      "source": [
        "def create_dataset(dataset, look_back):\r\n",
        "    '''\r\n",
        "    对数据进行处理\r\n",
        "    '''\r\n",
        "    dataX, dataY = [], []\r\n",
        "    for i in range (len (dataset) - (look_back * 2) -1, len (dataset) - look_back - 1):\r\n",
        "        a = dataset[i:(i + look_back), :]\r\n",
        "        dataX.append (a)\r\n",
        "        dataY.append (dataset[i + look_back, :])\r\n",
        "    TrainX = np.array (dataX)\r\n",
        "    Train_Y = np.array (dataY)\r\n",
        "\r\n",
        "    return TrainX, Train_Y\r\n",
        "\r\n",
        "# 多维归一化  返回数据和最大最小值\r\n",
        "def NormalizeMult(data):\r\n",
        "    # normalize 用于反归一化\r\n",
        "    data = np.array (data)\r\n",
        "    normalize = np.arange (2 * data.shape[1], dtype='float64')\r\n",
        "\r\n",
        "    normalize = normalize.reshape (data.shape[1], 2)\r\n",
        "    print (normalize.shape)\r\n",
        "    for i in range (0, data.shape[1]):\r\n",
        "        # 第i列\r\n",
        "        list = data[:, i]\r\n",
        "        listlow, listhigh = np.percentile (list, [0, 100])\r\n",
        "        # print(i)\r\n",
        "        normalize[i, 0] = listlow\r\n",
        "        normalize[i, 1] = listhigh\r\n",
        "        delta = listhigh - listlow\r\n",
        "        if delta != 0:\r\n",
        "            # 第j行\r\n",
        "            for j in range (0, data.shape[0]):\r\n",
        "                data[j, i] = (data[j, i] - listlow) / delta\r\n",
        "    # np.save(\"./normalize.npy\",normalize)\r\n",
        "    return data, normalize\r\n",
        "\r\n",
        "\r\n",
        "# 多维反归一化\r\n",
        "def FNormalizeMult(data, normalize):\r\n",
        "    data = np.array (data)\r\n",
        "    for i in range (0, data.shape[1]):\r\n",
        "        listlow = normalize[i, 0]\r\n",
        "        listhigh = normalize[i, 1]\r\n",
        "        delta = listhigh - listlow\r\n",
        "        if delta != 0:\r\n",
        "            # 第j行\r\n",
        "            for j in range (0, data.shape[0]):\r\n",
        "                data[j, i] = data[j, i] * delta + listlow\r\n",
        "\r\n",
        "    return data\r\n",
        "\r\n",
        "model = load_model ('bi-attention.h5')\r\n",
        "data = pd.read_excel ('imfs1.xls')\r\n",
        "data = data.drop (['number'], axis=1)\r\n",
        "# data = data.drop (['number', 'LR corr', 'LR loc', 'LS corr', 'LS loc'], axis=1)\r\n",
        "data = np.array(data)\r\n",
        "INPUT_DIMS = 7\r\n",
        "TIME_STEPS = 24\r\n",
        "data, normalize = NormalizeMult (data)\r\n",
        "test_X, _ = create_dataset(data, TIME_STEPS)\r\n",
        "print(test_X.shape)\r\n",
        "\r\n",
        "predictions = model.predict (test_X)\r\n",
        "predictions = FNormalizeMult(predictions, normalize)\r\n",
        "# MM = MinMaxScaler()\r\n",
        "#　predictions = MM.fit.inverse_transform (predictions)\r\n",
        "actual = FNormalizeMult(data[-24:, [0]], normalize)\r\n",
        "\r\n",
        "# plt.plot(FNormalizeMult(data[:, [0]],normalize))\r\n",
        "\r\n",
        "plt.plot(predictions)\r\n",
        "plt.plot(actual)\r\n",
        "plt.xlabel ('timestamp', fontsize=12)\r\n",
        "plt.ylabel ('load', fontsize=12)\r\n",
        "plt.show ()\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-fd7c1ddd201a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'bi-attention1.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'imfs1.xls'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'number'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    112\u001b[0m                   (export_dir,\n\u001b[1;32m    113\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: bi-attention1.h5/{saved_model.pbtxt|saved_model.pb}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsbJNSXYhnly"
      },
      "source": [
        "# 新段落"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65LjhmguhhKn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}